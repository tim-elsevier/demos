{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882eb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from termite_toolkit import termite \n",
    "from os import listdir\n",
    "from pprint import pprint\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "# VARIABLES\n",
    "termite_home = \"https://termite.scibite-mvp.nonprod.entellect.com/termite\"\n",
    "sdxml = [f for f in listdir() if f.endswith(\".xml\")]\n",
    "core_entities = \"ANAT,BIOCHEM,BIOPROC,CELLLINE,CELLTYP,COMPANY,COUNTRY,DBSNP,DRUG,GENE,GOONTOL,INDICATION,MEASURE,MIRNA,MOA,PROTYP,SPECIES\"\n",
    "options = {\"format\": \"node.xml\", \"output\": \"json\", \"entities\": core_entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3aa9d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = {'xocs': 'http://www.elsevier.com/xml/xocs/dtd',\n",
    "      'ja': 'http://www.elsevier.com/xml/ja/dtd',\n",
    "     'ce' :'http://www.elsevier.com/xml/common/dtd'}\n",
    "\n",
    "\n",
    "def xpath2string(value, method='normal'):\n",
    "        if method == 'normal':\n",
    "            try:\n",
    "                valuelist = []\n",
    "                for v in list(value):\n",
    "                    valuelist.append(v.text)\n",
    "                return \" : \".join(valuelist)\n",
    "            except TypeError:\n",
    "                return ''\n",
    "        elif method == 'greedy':\n",
    "            try:\n",
    "                valuelist = []\n",
    "                for v in list(value):\n",
    "                    valuelist.append(ET.tostring(v, method='text').decode(\"utf-8\"))\n",
    "                    #valuelist.append(\"\".join(map(chr, ET.tostring(v, method='text'))))\n",
    "                return \" \".join(valuelist)\n",
    "            except AttributeError:\n",
    "                return ''\n",
    "        elif method == 'names':\n",
    "            valuelist = []\n",
    "            for v in list(value):\n",
    "                surname_path = v.find('./ce:surname', ns)\n",
    "                forename_path = v.find('./ce:given-name', ns)\n",
    "                valuelist.append(dict(surname=surname_path.text, forename=forename_path.text))\n",
    "            return(valuelist)\n",
    "        \n",
    "def tag_using_etree():\n",
    "    termite_instance = termite.TermiteRequestBuilder()\n",
    "    termite_instance.set_url(termite_home)\n",
    "    termite_instance.set_input_format(\"xml\")\n",
    "    termite_instance.set_entities(core_entities)\n",
    "    count  = 0\n",
    "    for fn in sdxml:\n",
    "        \"\"\"\n",
    "        if count > 1:\n",
    "            break\n",
    "            \"\"\"\n",
    "        count +=1\n",
    "        metadata = {}\n",
    "        tree = ET.parse(fn)\n",
    "        root = tree.getroot()\n",
    "        jnl_path = tree.findall('.//xocs:srctitle', ns)\n",
    "        title_path = tree.findall('.//ce:title', ns)\n",
    "        abstract_path = tree.findall('.//ce:abstract-sec/ce:simple-para', ns)\n",
    "        affiliation_path = tree.findall('.//ce:affiliation/ce:textfn', ns)\n",
    "        pubdate_path = tree.findall('.//xocs:meta/xocs:available-online-date', ns)\n",
    "        author_path = tree.findall('.//ce:author-group/ce:author', ns)\n",
    "        doi_path = tree.findall('.//xocs:meta/xocs:doi',ns)\n",
    "        issn_path = tree.findall('.//xocs:issn-primary-unformatted',ns)\n",
    "        \n",
    "        metadata['pii'] = fn[:-4]\n",
    "        metadata['authors'] = xpath2string(author_path, method='names')\n",
    "        metadata['published'] = xpath2string(pubdate_path)\n",
    "        metadata['affiliations'] = xpath2string(affiliation_path)\n",
    "        metadata['abstract'] = xpath2string(abstract_path, method='greedy')\n",
    "        metadata['title'] = xpath2string(title_path, method='greedy')\n",
    "        metadata['journal'] = xpath2string(jnl_path)\n",
    "        metadata['doi'] = xpath2string(doi_path)\n",
    "        metadata['issn'] = xpath2string(issn_path)\n",
    "\n",
    "        #TODO explore whether we should come in at serial-article and not root\n",
    "        xmlstr = ET.tostring(root, encoding='utf8', method='xml')\n",
    "        termite_instance.set_text(xmlstr)\n",
    "        termite_response = termite_instance.execute()\n",
    "        payload = termite_response['RESP_MULTIDOC_PAYLOAD']['text']\n",
    "        metadata['entities'] = []\n",
    "        for entityType, entitylist in payload.items():\n",
    "            for e in entitylist:\n",
    "                wanted_keys = ['entityType', 'hitCount', 'name', 'hitID', 'taxon', 'frag_vector_array']\n",
    "                output = dict((k, e[k]) for k in wanted_keys if k in e)\n",
    "                metadata['entities'].append(output)\n",
    "        \n",
    "        with open(fn[:-4] + '.json', 'w') as outfile:\n",
    "            json.dump(metadata, outfile, indent=4)\n",
    "\n",
    "tag_using_etree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070dc4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
