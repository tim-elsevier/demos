{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36f66032",
   "metadata": {},
   "source": [
    "# FAIR Text Metadata generator\n",
    "## Processes XML files in current directory to generate JSON medatata\n",
    "### VERSION 1.0\n",
    "### DATE 5 August 2021\n",
    "### AUTHOR Tim Miller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "554c5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "from termite_toolkit import termite \n",
    "from os import listdir\n",
    "from pprint import pprint\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "# VARIABLES\n",
    "termite_home = \"https://termite.scibite-mvp.nonprod.entellect.com/termite\"\n",
    "sdxml = [f for f in listdir() if f.endswith(\".xml\")]\n",
    "core_entities = \"ANAT,BIOCHEM,BIOPROC,CELLLINE,CELLTYP,COMPANY,DBSNP,DRUG,GENE,GOONTOL,INDICATION,MEASURE,MIRNA,MOA,PROTYP,SPECIES\"\n",
    "options = {\"format\": \"any.xml\", \"output\": \"json\", \"entities\": core_entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ba797b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_dict(wanted_keys, input_dict):\n",
    "    output_dict = []\n",
    "    for e in input_dict:\n",
    "        output_dict.append(dict((k.title(), e[k]) for k in wanted_keys if k in e))\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7cee196",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = {'xocs': 'http://www.elsevier.com/xml/xocs/dtd',\n",
    "      'ja': 'http://www.elsevier.com/xml/ja/dtd',\n",
    "     'ce' :'http://www.elsevier.com/xml/common/dtd'}\n",
    "\n",
    "\n",
    "def xpath2string(value, method='normal'):\n",
    "        if method == 'normal':\n",
    "            try:\n",
    "                valuelist = []\n",
    "                for v in list(value):\n",
    "                    valuelist.append(v.text)\n",
    "                return \" : \".join(valuelist)\n",
    "            except TypeError:\n",
    "                return ''\n",
    "        elif method == 'greedy':\n",
    "            try:\n",
    "                valuelist = []\n",
    "                for v in list(value):\n",
    "                    valuelist.append(ET.tostring(v, method='text').decode(\"utf-8\"))\n",
    "                    #valuelist.append(\"\".join(map(chr, ET.tostring(v, method='text'))))\n",
    "                return \" \".join(valuelist)\n",
    "            except AttributeError:\n",
    "                return ''\n",
    "        elif method == 'names':\n",
    "            valuelist = []\n",
    "            for v in list(value):\n",
    "                surname_path = v.find('./ce:surname', ns)\n",
    "                forename_path = v.find('./ce:given-name', ns)\n",
    "                valuelist.append(dict(surname=surname_path.text, forename=forename_path.text))\n",
    "            return(valuelist)\n",
    "        \n",
    "def process_taxon(taxon):\n",
    "    \"\"\"\n",
    "    Tidy up the output of TERMite for hierarchies\n",
    "    \"\"\"\n",
    "    treeset = []\n",
    "    for taxo, tree in taxon.items():\n",
    "        treeset.extend([dict(TreePathCode=k, TreePath=v) for k,v in tree.items()])\n",
    "    return treeset\n",
    "        \n",
    "def tag_using_etree():\n",
    "    termite_instance = termite.TermiteRequestBuilder()\n",
    "    termite_instance.set_url(termite_home)\n",
    "    termite_instance.set_input_format(\"xml\")\n",
    "    termite_instance.set_entities(core_entities)\n",
    "    count  = 0\n",
    "    for fn in sdxml:\n",
    "        \"\"\"\n",
    "        if count > 1:\n",
    "            break\n",
    "            \"\"\"\n",
    "        count +=1\n",
    "        metadata = {}\n",
    "        tree = ET.parse(fn)\n",
    "        root = tree.getroot()\n",
    "        jnl_path = tree.findall('.//xocs:srctitle', ns)\n",
    "        title_path = tree.findall('.//ce:title', ns)\n",
    "        abstract_path = tree.findall('.//ce:abstract-sec/ce:simple-para', ns)\n",
    "        affiliation_path = tree.findall('.//ce:affiliation/ce:textfn', ns)\n",
    "        pubdate_path = tree.findall('.//xocs:meta/xocs:available-online-date', ns)\n",
    "        author_path = tree.findall('.//ce:author-group/ce:author', ns)\n",
    "        doi_path = tree.findall('.//xocs:meta/xocs:doi',ns)\n",
    "        issn_path = tree.findall('.//xocs:issn-primary-unformatted',ns)\n",
    "        cid_path = tree.findall('.//xocs:meta/xocs:cid',ns)\n",
    "        \n",
    "        metadata['PII'] = fn[:-4]\n",
    "        metadata['Authors'] = xpath2string(author_path, method='names')\n",
    "        metadata['PublicationDate'] = xpath2string(pubdate_path)\n",
    "        metadata['Affiliations'] = xpath2string(affiliation_path)\n",
    "        metadata['Abstract'] = xpath2string(abstract_path, method='greedy')\n",
    "        metadata['Title'] = xpath2string(title_path, method='greedy')\n",
    "        metadata['JournalTitle'] = xpath2string(jnl_path)\n",
    "        metadata['DOI'] = xpath2string(doi_path)\n",
    "        metadata['ISSN'] = xpath2string(issn_path)\n",
    "        metadata['CID'] = xpath2string(cid_path)\n",
    "        termite_response = termite.annotate_files(termite_home, fn, options)\n",
    "        payload = termite_response['RESP_MULTIDOC_PAYLOAD'][fn]\n",
    "        metadata['Entities'] = []\n",
    "        for entityType, entitylist in payload.items():\n",
    "            for e in entitylist:\n",
    "                wanted_keys = ['entityType', 'hitCount', 'name', 'hitID', 'taxon', 'exact_array', 'sectionMeta']\n",
    "                wanted_key_names = {'entityType': 'EntityType', 'hitCount': 'Frequency', 'name':'PreferredName', 'hitID':'ID', 'taxon':'HigherTerms', 'exact_array':'Locations', 'sectionMeta':'XPaths'}\n",
    "                output = dict((wanted_key_names[k], e[k]) for k in wanted_keys if k in e)\n",
    "                output['Locations'] = subset_dict(['sentence', 'start', 'end'], output['Locations'])\n",
    "                output['XPaths'] = [dict(Offset=x, Path=y[:-1]) for x,y in output['XPaths'].items()]\n",
    "                sections = []\n",
    "                for section in output['XPaths']:\n",
    "                    #print (section['Path'])\n",
    "                    if 'reference' in section['Path']:\n",
    "                        sections.append('REFERENCES')\n",
    "                    elif 'title' in section['Path']:\n",
    "                        sections.append('TITLE')\n",
    "                    elif 'abstract' in section['Path']:\n",
    "                        sections.append('ABSTRACT')\n",
    "                    elif 'article' in section['Path']:\n",
    "                        sections.append('ARTICLE')\n",
    "                    #print (sections)\n",
    "                sections = list(set(sections))\n",
    "\n",
    "                output['Sections'] = sections\n",
    "                \n",
    "                try:\n",
    "                    output['HigherTerms'] = process_taxon(output['HigherTerms'])\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                \n",
    "                metadata['Entities'].append(output)\n",
    "        \n",
    "        with open(fn[:-4] + '.json', 'w') as outfile:\n",
    "            json.dump(metadata, outfile, indent=4)\n",
    "\n",
    "tag_using_etree()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
